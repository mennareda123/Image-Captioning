import streamlit as st
import torch
import torch.nn as nn
from PIL import Image
import requests
import io
from torchvision import transforms
import pickle

# ============== Ø¥ØµÙ„Ø§Ø­ Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ ==============
def generate_caption(model, image_tensor, vocab, device, max_length=25):
    """Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…ØµØ­Ø­Ø©"""
    model.eval()
    with torch.no_grad():
        image_tensor = image_tensor.unsqueeze(0).to(device)
        features = model.encoder(image_tensor)
        
        # âœ… ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ù… '<SOS>' 
        caption = [vocab.stoi["<SOS>"]]
        
        # âœ… ØªØµØ­ÙŠØ­: hidden state Ù…Ù† decoder
        h = model.decoder.fc_h(features).unsqueeze(0)
        c = model.decoder.fc_c(features).unsqueeze(0)
        
        for _ in range(max_length):
            last_word = torch.tensor([caption[-1]]).to(device)
            # âœ… ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ù… decoder.embed
            embedding = model.decoder.embed(last_word).unsqueeze(1)
            
            lstm_out, (h, c) = model.decoder.lstm(embedding, (h, c))
            output = model.decoder.linear(lstm_out.squeeze(1))
            
            predicted = output.argmax(1).item()
            caption.append(predicted)
            
            # âœ… ØªØµØ­ÙŠØ­: ØªÙˆÙ‚Ù Ø¹Ù†Ø¯ <EOS>
            if predicted == vocab.stoi["<EOS>"]:
                break
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª
        words = []
        for idx in caption[1:]:  # ØªØ®Ø·ÙŠ <SOS>
            if idx == vocab.stoi["<EOS>"]:
                break
            if idx in vocab.itos and idx not in [vocab.stoi["<PAD>"]]:
                words.append(vocab.itos[idx])
        
        return " ".join(words)

# ============== Ø¨Ù‚ÙŠØ© Ø§Ù„Ù€GUI ==============
@st.cache_resource
def load_vocab():
    with open("vocab.pkl", "rb") as f:
        return pickle.load(f)

@st.cache_resource  
def load_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† try1
    from try1 import CaptionModel, Vocabulary
    
    # ØªØ­Ù…ÙŠÙ„ vocab Ø§Ù„ÙØ¹Ù„ÙŠ
    with open("vocab.pkl", "rb") as f:
        vocab = pickle.load(f)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = CaptionModel(
        embed_size=256,
        hidden_size=512,
        vocab_size=len(vocab.itos)
    )
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
    model.load_state_dict(torch.load("caption_model.pth", map_location=device))
    model.to(device)
    model.eval()
    
    return model, vocab, device

# ============== ÙˆØ§Ø¬Ù‡Ø© Streamlit ==============
st.set_page_config(
    page_title="ğŸ¤– Ù†Ø¸Ø§Ù… ÙˆØµÙ Ø§Ù„ØµÙˆØ±",
    page_icon="ğŸ–¼ï¸",
    layout="wide"
)

# CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .result-box {
        padding: 1.5rem;
        background: #f8f9fa;
        border-radius: 10px;
        border-left: 5px solid #4CAF50;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="main-header"><h1>ğŸ–¼ï¸ Ù†Ø¸Ø§Ù… ÙˆØµÙ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø°ÙƒÙŠ</h1></div>', unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown("### âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    max_length = st.slider("Ø·ÙˆÙ„ Ø§Ù„ÙˆØµÙ", 10, 40, 20)
    st.markdown("---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„..."):
            if 'model' not in st.session_state:
                model, vocab, device = load_model()
                st.session_state.model = model
                st.session_state.vocab = vocab
                st.session_state.device = device
                st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
            else:
                st.info("âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„")

# ØªØ¨ÙˆÙŠØ¨Ø§Øª
tab1, tab2 = st.tabs(["ğŸ“¤ Ø±ÙØ¹ ØµÙˆØ±Ø©", "ğŸ”— Ø±Ø§Ø¨Ø· Ø¥Ù†ØªØ±Ù†Øª"])

with tab1:
    st.markdown("### Ø±ÙØ¹ ØµÙˆØ±Ø©")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png', 'jpeg'])
    
    if uploaded_file and 'model' in st.session_state:
        col1, col2 = st.columns(2)
        
        with col1:
            image = Image.open(uploaded_file).convert('RGB')
            st.image(image, use_column_width=True)
            
        with col2:
            if st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆØµÙ..."):
                    try:
                        transform = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                        ])
                        
                        img_tensor = transform(image)
                        caption = generate_caption(
                            st.session_state.model,
                            img_tensor,
                            st.session_state.vocab,
                            st.session_state.device,
                            max_length
                        )
                        
                        st.markdown(f"""
                        <div class="result-box">
                            <h4>ğŸ“ Ø§Ù„ÙˆØµÙ:</h4>
                            <p style="font-size: 18px; color: #1E3A8A;">
                            {caption}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙ
                        words = caption.split()
                        col_stats = st.columns(3)
                        col_stats[0].metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", len(words))
                        col_stats[1].metric("ÙƒÙ„Ù…Ø§Øª ÙØ±ÙŠØ¯Ø©", len(set(words)))
                        col_stats[2].metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø·ÙˆÙ„", f"{sum(len(w) for w in words)/len(words):.1f}")
                        
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£: {str(e)}")

with tab2:
    st.markdown("### Ø±Ø§Ø¨Ø· ØµÙˆØ±Ø©")
    url = st.text_input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©")
    
    if url and 'model' in st.session_state:
        try:
            response = requests.get(url, timeout=10)
            image = Image.open(io.BytesIO(response.content)).convert('RGB')
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(image, use_column_width=True)
                
            with col2:
                if st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ", key="url"):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆØµÙ..."):
                        transform = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                        ])
                        
                        img_tensor = transform(image)
                        caption = generate_caption(
                            st.session_state.model,
                            img_tensor,
                            st.session_state.vocab,
                            st.session_state.device,
                            max_length
                        )
                        
                        st.success(f"**Ø§Ù„ÙˆØµÙ:** {caption}")
                        
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")

# Ù…Ù„Ø§Ø­Ø¸Ø©
if 'model' not in st.session_state:
    st.info("âš ï¸ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ 'ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬' ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ø§Ù‹")